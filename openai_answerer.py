# -*- coding: utf-8 -*-
import os
import re
import html
import logging
from typing import List, Dict, Any, Optional, Tuple

try:
    # Optional dependency. If the package isn't installed, we only fail when the
    # feature is actually enabled/used.
    from openai import OpenAI  # type: ignore
except Exception:  # pragma: no cover
    OpenAI = None  # type: ignore

logger = logging.getLogger(__name__)


class OpenAIAnswerer:
    """
    Answerer Ù…Ù‚ÙŠØ¯ Ø¨Ø§Ù„Ù…ØµØ¯Ø±:
    - Ø¨ÙŠØ§Ø®Ø¯ Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… + Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø« (messages)
    - ÙŠØ¬Ø§ÙˆØ¨ ÙÙ‚Ø· Ù…Ù† Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ Ø§Ù„Ù„ÙŠ Ø§ØªØ¨Ø¹ØªØªÙ„Ù‡
    - Ù„Ùˆ Ù…Ø´ Ù…ÙˆØ¬ÙˆØ¯: ÙŠÙ‚ÙˆÙ„ "ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ø¯Ø§ØªØ§" (Ø¯Ø§Ø®Ù„ÙŠÙ‹Ø§) Ø«Ù… Ù†Ø·Ø¨Ù‘Ù‚ ÙÙˆØ±Ù…Ø§Øª Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨.
    - Ø¨ÙŠØ±Ø¬Ø¹ Ù†Øµ HTML Ø¢Ù…Ù† Ù„ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù… (ParseMode.HTML)
      * Ù…Ù…Ù†ÙˆØ¹ Ø£ÙŠ HTML Ù…Ù† Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ â€” Ø¨Ù†Ø¹Ù…Ù„ escape Ø¨Ø§Ù„ÙƒØ§Ù…Ù„.
    """

    NO_ANSWER_MSG = "Ù„Ù‚Ø¯ Ø¨Ø­Ø«Øª ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© ÙˆÙ„Ù… Ø§Ø¬Ø¯ Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ø³ØªÙØ³Ø§Ø±Ùƒ"

    def __init__(self, api_key: Optional[str] = None, model: str = "gpt-4o-mini"):
        if OpenAI is None:
            raise ModuleNotFoundError(
                "The 'openai' package is not installed. Install it (pip install openai) "
                "or disable USE_OPENAI_ANSWER in your environment."
            )
        api_key = (api_key or os.environ.get("OPENAI_API_KEY", "")).strip()
        if not api_key:
            raise ValueError("OPENAI_API_KEY is missing")
        self.client = OpenAI(api_key=api_key)
        self.model = (model or "gpt-4o-mini").strip()

    # -----------------------------
    # Helpers
    # -----------------------------
    @staticmethod
    def _clean(s: str) -> str:
        s = (s or "").strip()
        s = re.sub(r"\n{3,}", "\n\n", s)
        return s

    @staticmethod
    def _truncate(s: str, n: int) -> str:
        s = (s or "")
        return s[:n] + ("â€¦" if len(s) > n else "")

    @staticmethod
    def _safe(s: str) -> str:
        # Escape Ù„Ø£ÙŠ HTML Ø¹Ø´Ø§Ù† ParseMode.HTML Ù…Ø§ ÙŠØªÙƒØ³Ø±Ø´
        return html.escape(s or "")

    @staticmethod
    def _normalize_headings(t: str) -> str:
        """Normalize common alternative headings produced by the model."""
        t = (t or "")
        t = t.replace("âœ… Ø¥Ø¬Ø§Ø¨Ø© Ù…Ø®ØªØµØ±Ø©", "âœ… Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©")
        t = t.replace("ğŸ§¾ ØªÙØ§ØµÙŠÙ„", "ğŸ§  Ø§Ù„Ø´Ø±Ø­")
        return t

    @staticmethod
    def _dedupe_consecutive_lines(s: str) -> str:
        """Remove consecutive duplicate lines and extra blank lines."""
        lines = (s or "").splitlines()
        out: List[str] = []
        for ln in lines:
            raw = ln.rstrip()
            stripped = raw.strip()

            # collapse multiple blank lines
            if not stripped:
                if out and out[-1] == "":
                    continue
                out.append("")
                continue

            # drop consecutive duplicates (ignoring surrounding spaces)
            if out and out[-1].strip() == stripped:
                continue
            out.append(raw)

        return "\n".join(out).strip()

    @staticmethod
    def _is_no_data(s: str) -> bool:
        """Detect the no-answer condition."""
        t = (s or "").strip()
        if not t:
            return True
        if "ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ø¯Ø§ØªØ§" in t:
            return True
        # Sometimes the model writes our user-facing phrasing directly.
        if OpenAIAnswerer.NO_ANSWER_MSG in t:
            return True
        if "Ù„Ù… Ø§Ø¬Ø¯" in t and "Ø¥Ø¬Ø§Ø¨Ø©" in t and "Ø§Ù„Ø°Ø§ÙƒØ±Ø©" in t:
            return True
        if "Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø±Ø§Ø¬Ø¹" in t:
            return True
        return False

    def _split_answer_and_more(self, model_text: str) -> Tuple[str, str]:
        """Extract (answer, more) from model output (supports old/new formats)."""
        t = self._clean(model_text)
        # Remove any accidental "sources" tail
        t = re.sub(r"ğŸ”—\s*Ù…ØµØ§Ø¯Ø±.*$", "", t, flags=re.DOTALL).strip()
        t = self._normalize_headings(t)

        # New format: <answer>\n\nğŸ§  Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª\n<more>
        if "ğŸ§  Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª" in t:
            left, right = t.split("ğŸ§  Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª", 1)
            answer = left.strip()
            more = right.strip()
            # Drop any stray old headings in the answer part
            answer_lines = [ln.strip() for ln in answer.splitlines() if ln.strip()]
            answer_lines = [ln for ln in answer_lines if ln not in {"âœ… Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©", "ğŸ§  Ø§Ù„Ø´Ø±Ø­"}]
            answer = "\n".join(answer_lines).strip()
            return (answer, more)

        # Old format: âœ… Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© ...\n\nğŸ§  Ø§Ù„Ø´Ø±Ø­ ...
        lines = [ln.rstrip() for ln in t.splitlines()]
        ans_i = None
        exp_i = None
        for i, ln in enumerate(lines):
            if ans_i is None and ln.strip() == "âœ… Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©":
                ans_i = i
                continue
            if exp_i is None and ln.strip() in {"ğŸ§  Ø§Ù„Ø´Ø±Ø­", "ğŸ§  Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª"}:
                exp_i = i

        if ans_i is not None and exp_i is not None and exp_i > ans_i:
            answer = "\n".join(lines[ans_i + 1 : exp_i]).strip()
            more = "\n".join(lines[exp_i + 1 :]).strip()
            return (answer, more)

        # Fallback: treat whole output as answer only.
        # We can mirror it later under "ğŸ§  Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª" if needed.
        t2 = t.strip()
        return (t2, "")

    def _format_final_output(self, model_text: str) -> str:
        """Return the final Telegram-ready HTML-safe output with the requested format."""
        answer, more = self._split_answer_and_more(model_text)

        # No-answer condition -> fixed text in both sections
        if self._is_no_data(answer) or self._is_no_data(more):
            msg = self.NO_ANSWER_MSG
            final_plain = f"{msg}\n\nğŸ§  Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª\n{msg}"
            return self._safe(final_plain)

        answer = (answer or "").strip()
        more = (more or "").strip()

        # Remove repeated lines that make the UX noisy.
        answer = self._dedupe_consecutive_lines(answer)
        more = self._dedupe_consecutive_lines(more)

        # If one side is empty, mirror the other
        if not answer and more:
            answer = more
        if not more and answer:
            more = answer

        final_plain = f"{answer}\n\nğŸ§  Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª\n{more}"
        return self._safe(final_plain)

    # -----------------------------
    # Build references
    # -----------------------------
    def build_refs(
        self,
        results: List[Dict[str, Any]],
        max_items: int = 8,
        max_chars_each: int = 800
    ) -> str:
        """
        ÙŠØ±Ø¬Ø¹ Ù†Øµ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ Ø§Ù„Ù„ÙŠ Ù‡Ù†Ø¨Ø¹ØªÙ‡ Ù„Ù„Ù…ÙˆØ¯ÙŠÙ„ (Ø¨Ø¯ÙˆÙ† Ø±ÙˆØ§Ø¨Ø· â€” Ø¹Ø´Ø§Ù† Ù†ÙØ¶Ù„ Ù…Ù‚ÙŠØ¯ÙŠÙ† Ø¨Ø§Ù„Ù…ØµØ¯Ø± ÙÙ‚Ø·)
        """
        chunks: List[str] = []

        for i, item in enumerate((results or [])[:max_items], start=1):
            seed = item.get("seed", {}) or {}

            msg = self._clean(seed.get("message") or "")
            user = (seed.get("user") or seed.get("username") or "").strip()
            date_str = (seed.get("date_str") or "").strip()

            # Ø¶ÙŠÙ Ø£ÙØ¶Ù„ Ø±Ø¯ Ù„Ùˆ Ù…ÙˆØ¬ÙˆØ¯ (Ø¨ÙŠØ­Ø³Ù† Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©)
            best_reply_text = ""
            try:
                br = item.get("best_reply")
                if isinstance(br, (list, tuple)) and len(br) == 2 and isinstance(br[1], dict):
                    br_meta = br[1]
                    br_msg = self._clean(br_meta.get("message") or "")
                    if br_msg:
                        best_reply_text = f"\n\n[Ø£ÙØ¶Ù„ Ø±Ø¯]\n{br_msg}"
            except Exception:
                pass

            # Ø¶ÙŠÙ Ø¨Ø¹Ø¶ Ø§Ù„Ø±Ø¯ÙˆØ¯ Ø§Ù„Ø£Ø®Ø±Ù‰ (Ø¥Ù† ÙˆÙØ¬Ø¯Øª) â€” Ø¨Ø¯ÙˆÙ† Ø±ÙˆØ§Ø¨Ø·
            try:
                reps = item.get("replies") or []
                shown = 0
                extra_parts = []
                for rr in reps:
                    if shown >= 3:
                        break
                    if isinstance(rr, (list, tuple)) and len(rr) >= 2 and isinstance(rr[1], dict):
                        r_meta = rr[1]
                    elif isinstance(rr, dict):
                        r_meta = rr
                    else:
                        continue
                    r_msg = self._clean(r_meta.get("message") or "")
                    if not r_msg:
                        continue
                    extra_parts.append(r_msg)
                    shown += 1
                if extra_parts:
                    best_reply_text = (best_reply_text or "") + "\n\n[Ø±Ø¯ÙˆØ¯ Ø£Ø®Ø±Ù‰]\n" + "\n---\n".join(extra_parts)
            except Exception:
                pass

            msg = self._truncate(msg, max_chars_each)
            if best_reply_text:
                best_reply_text = self._truncate(best_reply_text, max_chars_each)

            chunks.append(f"[{i}] ({date_str}) {user}\n{msg}{best_reply_text}".strip())

        return "\n\n---\n\n".join(chunks).strip()

    # -----------------------------
    # Main (non-streaming)
    # -----------------------------
    def answer(
        self,
        question: str,
        results: List[Dict[str, Any]],
        max_items: int = 8,
        max_chars: int = 800,
    ) -> str:
        question = (question or "").strip()
        if not question:
            return self._safe("âŒ Ø³Ø¤Ø§Ù„ ÙØ§Ø±Øº.")

        refs_text = self.build_refs(results, max_items=max_items, max_chars_each=max_chars)
        if not refs_text:
            # Ø¯ÙŠ Ø±Ø³Ø§Ù„Ø© Ø¯Ø§Ø®Ù„ÙŠØ© Ø«Ø§Ø¨ØªØ© (Ù…Ø´ Ù…Ù† Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„)
            return self._format_final_output("ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ø¯Ø§ØªØ§.")

        # Prompt ØµØ§Ø±Ù…: Ø¨Ø¯ÙˆÙ† Ù…ØµØ§Ø¯Ø± + Ù…Ù…Ù†ÙˆØ¹ HTML/Ø±ÙˆØ§Ø¨Ø·
        system = (
            "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ ÙŠØ¬ÙŠØ¨ ÙÙ‚Ø· Ù…Ù† (Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹) Ø§Ù„Ù…Ø±ÙÙ‚Ø©.\n"
            "Ù‚ÙˆØ§Ø¹Ø¯ ØµØ§Ø±Ù…Ø©:\n"
            "1) Ù…Ù…Ù†ÙˆØ¹ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£ÙŠ Ù…Ø¹Ø±ÙØ© Ø®Ø§Ø±Ø¬ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹.\n"
            "2) Ù…Ù…Ù†ÙˆØ¹ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ Ø£Ùˆ Ø§Ù„ØªØ®Ù…ÙŠÙ†.\n"
            "3) Ù„Ùˆ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø© ØµØ±Ø§Ø­Ø© ÙÙŠ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹: Ù„Ø§ ØªØ®ØªØ±Ø¹.\n"
            "4) Ù…Ù…Ù†ÙˆØ¹ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£ÙŠ ÙˆØ³ÙˆÙ… HTML Ø£Ùˆ Ø±ÙˆØ§Ø¨Ø· Ø¯Ø§Ø®Ù„ Ø§Ù„Ù†Øµ.\n"
            "5) Ø§Ù„ØªØ²Ù… ÙÙˆØ±Ù…Ø§Øª Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ EXACT Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ø£Ù‚Ø³Ø§Ù… Ø¥Ø¶Ø§ÙÙŠØ©:\n\n"
            "âœ… Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©\n"
            "<Ø¥Ø¬Ø§Ø¨Ø© Ù…Ø®ØªØµØ±Ø©> Ø£Ùˆ: ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ø¯Ø§ØªØ§.\n\n"
            "ğŸ§  Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª\n"
            "<Ù†Ù‚Ø§Ø· Ù‚ØµÙŠØ±Ø© (3-7) ØªÙˆØ¶Ø­ Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ù…Ù† Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ ÙÙ‚Ø·> Ø£Ùˆ: ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ø¯Ø§ØªØ§.\n"
        )

        user = (
            f"Ø§Ù„Ø³Ø¤Ø§Ù„:\n{question}\n\n"
            f"Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ (Ø§Ù„Ù…ØµØ¯Ø± Ø§Ù„ÙˆØ­ÙŠØ¯):\n{refs_text}\n\n"
            "Ø§ÙƒØªØ¨ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠ ÙˆØ¨Ù†ÙØ³ Ø§Ù„ÙÙˆØ±Ù…Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©."
        )

        try:
            resp = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system},
                    {"role": "user", "content": user},
                ],
                temperature=0.0,
            )
            content = (resp.choices[0].message.content or "").strip()
        except Exception as e:
            logger.exception("OpenAI answer failed: %s", e)
            return self._safe("âš ï¸ Ø­ØµÙ„ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©.")

        return self._format_final_output(content)

    # -----------------------------
    # Main (streaming)
    # -----------------------------
    def stream_answer(
        self,
        question: str,
        results: List[Dict[str, Any]],
        max_items: int = 8,
        max_chars: int = 800,
    ):
        """
        Stream model output as text deltas (no HTML) using chat.completions streaming.
        Important:
        - Ø¯ÙŠ Ø§Ù„ØªØ¯ÙÙ‘Ù‚Ø§Øª Ø®Ø§Ù… (Ø¨Ø¯ÙˆÙ† HTML).
        - Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ (Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª...) Ø¨ÙŠØªÙ… ÙÙŠ Ø§Ù„Ù‡Ø§Ù†Ø¯Ù„Ø± Ø¨Ø¹Ø¯ Ø§Ù„ØªØ¬Ù…ÙŠØ¹ØŒ
          Ø£Ùˆ ØªÙ‚Ø¯Ø± ØªØ³ØªØ®Ø¯Ù… _format_final_output Ù„Ùˆ Ù…Ø´ Ù‡ØªØ¹Ù…Ù„ preview Ø­ÙŠÙ‘Ø©.
        """
        question = (question or "").strip()
        if not question:
            yield "âŒ Ø³Ø¤Ø§Ù„ ÙØ§Ø±Øº."
            return

        refs_text = self.build_refs(results, max_items=max_items, max_chars_each=max_chars)
        if not refs_text:
            # Ø®Ù„ÙŠÙ‡Ø§ Ø¨Ù†ÙØ³ Ø§Ù„Ù…Ù†Ø·Ù‚: Ù†Ø·Ù„Ø¹ "ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ø¯Ø§ØªØ§" (ÙˆØ§Ù„Ù‡Ø§Ù†Ø¯Ù„Ø± ÙŠØ­ÙˆÙ„Ù‡Ø§ Ù„Ù„ØµÙŠØºØ© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©)
            yield "ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ø¯Ø§ØªØ§."
            return
        system = (
            "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ ÙŠØ¬ÙŠØ¨ ÙÙ‚Ø· Ù…Ù† (Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹) Ø§Ù„Ù…Ø±ÙÙ‚Ø©.\n"
            "Ù‚ÙˆØ§Ø¹Ø¯ ØµØ§Ø±Ù…Ø©:\n"
            "1) Ù…Ù…Ù†ÙˆØ¹ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£ÙŠ Ù…Ø¹Ø±ÙØ© Ø®Ø§Ø±Ø¬ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹.\n"
            "2) Ù…Ù…Ù†ÙˆØ¹ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ Ø£Ùˆ Ø§Ù„ØªØ®Ù…ÙŠÙ†.\n"
            "3) Ù„Ùˆ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø© ØµØ±Ø§Ø­Ø© ÙÙŠ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹: Ù„Ø§ ØªØ®ØªØ±Ø¹.\n"
            "4) Ù…Ù…Ù†ÙˆØ¹ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£ÙŠ ÙˆØ³ÙˆÙ… HTML Ø£Ùˆ Ø±ÙˆØ§Ø¨Ø· Ø¯Ø§Ø®Ù„ Ø§Ù„Ù†Øµ.\n"
            "5) Ø§Ù„ØªØ²Ù… ÙÙˆØ±Ù…Ø§Øª Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ EXACT Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ø£Ù‚Ø³Ø§Ù… Ø¥Ø¶Ø§ÙÙŠØ©:\n\n"
            "âœ… Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©\n"
            "<Ø¥Ø¬Ø§Ø¨Ø© Ù…Ø®ØªØµØ±Ø©> Ø£Ùˆ: ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ø¯Ø§ØªØ§.\n\n"
            "ğŸ§  Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª\n"
            "<Ù†Ù‚Ø§Ø· Ù‚ØµÙŠØ±Ø© (3-7) ØªÙˆØ¶Ø­ Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ù…Ù† Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ ÙÙ‚Ø·> Ø£Ùˆ: ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ø¯Ø§ØªØ§.\n"
        )

        user = (
            f"Ø§Ù„Ø³Ø¤Ø§Ù„:\n{question}\n\n"
            f"Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ (Ø§Ù„Ù…ØµØ¯Ø± Ø§Ù„ÙˆØ­ÙŠØ¯):\n{refs_text}\n\n"
            "Ø§ÙƒØªØ¨ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠ ÙˆØ¨Ù†ÙØ³ Ø§Ù„ÙÙˆØ±Ù…Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©."
        )

        try:
            stream = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system},
                    {"role": "user", "content": user},
                ],
                temperature=0.0,
                stream=True,
            )
            for event in stream:
                try:
                    delta = event.choices[0].delta.content
                except Exception:
                    delta = None
                if delta:
                    yield delta
            return
        except Exception as e:
            logger.warning("OpenAI streaming failed, falling back to non-streaming: %s", e)

        # Fallback: non-streaming
        try:
            resp = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system},
                    {"role": "user", "content": user},
                ],
                temperature=0.0,
            )
            content = (resp.choices[0].message.content or "").strip()
            content = self._clean(content)
            content = re.sub(r"ğŸ”—\s*Ù…ØµØ§Ø¯Ø±.*$", "", content, flags=re.DOTALL).strip()
            yield content
        except Exception as e:
            logger.exception("OpenAI answer failed: %s", e)
            yield "âš ï¸ Ø­ØµÙ„ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©."
